diff --git a/packages/ai/openai/src/Generated.ts b/packages/ai/openai/src/Generated.ts
index 5e06e0ff8..4c7d92bd2 100644
--- a/packages/ai/openai/src/Generated.ts
+++ b/packages/ai/openai/src/Generated.ts
@@ -1229,7 +1229,7 @@ export class ChatCompletionTokenLogprob extends S.Class<ChatCompletionTokenLogpr
  *
  *   When this parameter is set, the response body will include the `service_tier` utilized.
  */
-export class ServiceTier extends S.Literal("auto", "default", "flex") {}
+export class ServiceTier extends S.Literal("auto", "default", "flex", "scale") {}
 
 /**
  * The object type, which is always `chat.completion`.
@@ -1327,7 +1327,7 @@ export class CreateChatCompletionResponse
       /**
        * Log probability information for the choice.
        */
-      "logprobs": S.NullOr(S.Struct({
+      "logprobs": S.optional(S.NullOr(S.Struct({
         /**
          * A list of message content tokens with log probability information.
          */
@@ -1336,7 +1336,7 @@ export class CreateChatCompletionResponse
          * A list of message refusal tokens with log probability information.
          */
         "refusal": S.NullOr(S.Array(ChatCompletionTokenLogprob))
-      }))
+      })))
     })),
     /**
      * The Unix timestamp (in seconds) of when the chat completion was created.
@@ -3111,7 +3111,7 @@ export class Eval extends S.Class<Eval>("Eval")({
       EvalPythonGrader,
       EvalScoreModelGrader
     )
-  ).pipe(S.propertySignature, S.withConstructorDefault(() => "eval" as const)),
+  ),
   /**
    * The Unix timestamp (in seconds) for when the eval was created.
    */
